---
title: "stat151a_cleaned"
author: "Kelly Trinh"
date: "12/11/2020"
output: html_document
---

https://www.rdocumentation.org/packages/fivethirtyeight/versions/0.6.1/topics/college_recent_grads


```{r Libraries, message=FALSE, warning=FALSE}
library(fivethirtyeight) #source of data
library(corrplot) #correlation plot
library(dplyr) #data frame manipulation
library(ggplot2) #plotting
library(leaps)#variable selection: adjr2, bic, cp
library(olsrr)#variable selection: aic, p-val
library(car) # Anova
library(fastDummies)
library(faraway)
library(caret)
```

### Data cleaning 
```{r data_cleaning}

# load data
crg <- college_recent_grads
crg <- na.omit(crg)
# viewing correlations 
crg["log_median"] <- log(crg$median)
crg["college_job_prop"] <- crg$college_jobs / (crg$college_jobs + crg$non_college_jobs)
crg["full_time_yearround_prop"] <- crg$employed_fulltime_yearround / crg$employed
crg <- na.omit(crg)
cont <- select_if(crg, is.numeric)
cont <- na.omit(cont)
corrplot(cor(cont), type = "upper", order = "AOE")

# transform data
standardized <- data.frame(scale(cont))
major_category <- crg$major_category
crg <- cbind(standardized, major_category)

# temporary data frame to use later 
temp <- crg 

# transform categorical variable 
crg <- dummy_cols(crg, select_columns = "major_category", remove_selected_col = TRUE,remove_first_dummy = TRUE)
column_names <- make.names(names(crg),unique=TRUE)
colnames(crg) <- column_names


# test train split 
set.seed(11)
#randomly take 2:8 of data for training
training_size <- sample(dim(crg)[1],nrow(crg)*0.8)
training_data <- crg[training_size,]
testing_data <- crg[-training_size,]

```

```{r visualizations }

# major category versus median income 
ggplot(aes(x = major_category, y = log_median), data = temp) + geom_boxplot() + coord_flip()

```

### Variable selection without interactions

```{r prepare_data_for_selection}
Y <- as.matrix(crg$log_median)

X <- as.matrix(subset(crg,select=-c(log_median,median, major_code, p25th, p75th)))
# Check for linear dependencies, remove "men" or "total"
alias(lm(Y~X))
X <- as.matrix(subset(crg,select=-c(log_median,median, major_code, p25th, p75th,  men)))
```


```{r backward_forward}

#Forward Selection
model <- regsubsets(x = X, y = Y, method = "forward", nbest = 1) %>% summary()

adjustr2 <- model$adjr2
BIC <- model$bic
mallow_Cp <- model$cp


cbind(model$which[which.max(adjustr2),], model$which[which.min(BIC),],model$which[which.min(mallow_Cp),])

#Backward Selection

model <- regsubsets(x = X, y = Y, method = "backward", nbest = 1) %>% summary()


adjustr2 <- model$adjr2
BIC <- model$bic
mallow_Cp <- model$cp
cbind(model$which[which.max(adjustr2),], model$which[which.min(BIC),],model$which[which.min(mallow_Cp),])

```

```{r}
# Backward Adjusted R-squared CV
tc <- trainControl(method = "LOOCV")
b_adjr2_mod_cv <- train(log_median ~ employed + employed_fulltime_yearround + 
                          college_job_prop +
                          major_category_Biology...Life.Science+
                          major_category_Computers...Mathematics + 
                          rank + sharewomen + major_category_Engineering , 
                        data = training_data, method = "lm", trControl = tc)
b_adjr2_mod_cv.rmse <- b_adjr2_mod_cv$results[,"RMSE"]

```


```{r}
# Backward BIC CV
b_bic_mod_cv <- train(log_median ~ rank + college_job_prop +  major_category_Engineering, data = training_data, method = "lm", trControl = tc )
b_bic_mod_cv.rmse <- b_bic_mod_cv$results[, "RMSE"]
```

```{r}
# Backward Mallow's Cp CV
b_cp_mod_cv <- train(log_median ~ employed + employed_fulltime_yearround + 
                       college_job_prop +  major_category_Biology...Life.Science
                     + major_category_Computers...Mathematics + rank +
                       major_category_Engineering + sharewomen , data = training_data , 
                     method = "lm", trControl = tc)
b_cp_mod_cv.rmse <- b_cp_mod_cv$results[, "RMSE"]
```


```{r}
# Forward Adjusted R-squared CV
f_adjr2_model_cv <- train(log_median ~ rank + unemployment_rate + 
                           college_job_prop + major_category_Arts + 
                           major_category_Biology...Life.Science  + 
                           major_category_Engineering  + 
                           major_category_Humanities...Liberal.Arts  + 
                           major_category_Industrial.Arts...Consumer.Services , 
                           data = training_data, method = "lm", trControl = tc)

f_adjr2_model_cv.rmse <- f_adjr2_model_cv$results[, "RMSE"]

# Forward BIC CV
f_BIC_model_cv <- train(log_median ~ rank + college_job_prop + 
                           major_category_Engineering, 
                       data = training_data, method = "lm", trControl = tc)

f_BIC_model_cv.rmse <- f_BIC_model_cv$results[, "RMSE"]

# Forward Mallow's Cp CV
f_Cp_model_cv <- train(log_median ~ rank + unemployment_rate + 
                          college_job_prop + major_category_Arts + 
                         major_category_Engineering + 
                         major_category_Humanities...Liberal.Arts, 
                      data = training_data, method = "lm", trControl = tc)

f_Cp_model_cv.rmse <- f_Cp_model_cv$results[, "RMSE"]
```

```{r check_overfitting}
#checking for overfitting

# model selected from backward/forward selection 
model.backfor <- lm(log_median ~ employed + employed_fulltime_yearround + 
                          college_job_prop +
                          major_category_Biology...Life.Science+
                          major_category_Computers...Mathematics + 
                          rank + sharewomen + major_category_Engineering, 
                    data = training_data)

model.backfor_predict <- predict(model.backfor, newdata = testing_data, type = "response")

# sum of error squared 
sum((testing_data$log_median - model.backfor_predict)^2)

# correlation between actual values and predicted values 
cor(model.backfor_predict, testing_data$log_median)**2

```


Summary table description: 

`forward.rmse` and `backward.rmse` are columns with the RMSE from prediction on the testing dataset depending on either forward selection or backward selection. 
Each of the row represent the criteria in which to choose the model from either forward or backward selection: `Adjusted R squared`, `BIC`, `Mallow's Cp`. 

```{r CV_rmse_summary}

criterias <- c("Adjusted R squared", "BIC", "Mallow's Cp")
forward.rmse <- c(f_adjr2_model_cv.rmse, f_BIC_model_cv.rmse, f_Cp_model_cv.rmse)
backward.rmse <- c(b_adjr2_mod_cv.rmse, b_bic_mod_cv.rmse, b_cp_mod_cv.rmse)

# table of RMSE of each model 
data.frame(criterias, forward.rmse, backward.rmse)
```

### Variable selection with interactions 


```{r coplots, warning=FALSE, message=FALSE}
#interactions

# these co-plots do not contain some major categories because there are two few rows for each of those major categories

# temp dataframe for co-plots
temp.training <- temp[temp$rank %in% training_data$rank,]
temp.coplot <- temp.training[temp.training$major_category %in% 
                               c("Biology & Life Science",
                                 "Computers & Mathematics", 
                                 "Engineering"), ]


# share women and median income 
xyplot(log_median ~ sharewomen | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})

# rank and median income 
xyplot(log_median ~ rank | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})

# college job proportion and median income 
xyplot(log_median ~ college_job_prop | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})

# employed fulltime and median income 
xyplot(log_median ~ employed_fulltime_yearround | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})


```


```{r full_model_interactions}
# model selected from backward/forward selection 
model.backfor <- lm(log_median ~ employed + employed_fulltime_yearround + 
                          college_job_prop +
                          major_category_Biology...Life.Science+
                          major_category_Computers...Mathematics + 
                          rank + sharewomen + major_category_Engineering, 
                    data = training_data)

# full model with all the interaction terms 
model.interacts <- lm(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Biology...Life.Science * rank+
                        major_category_Computers...Mathematics * rank+ 
                        major_category_Engineering * rank +
                        major_category_Biology...Life.Science * sharewomen+
                        major_category_Computers...Mathematics * sharewomen + 
                        major_category_Engineering * sharewomen +
                        major_category_Biology...Life.Science * employed_fulltime_yearround+
                        major_category_Computers...Mathematics * employed_fulltime_yearround+ 
                        major_category_Engineering * employed_fulltime_yearround+
                        major_category_Biology...Life.Science * college_job_prop+
                        major_category_Computers...Mathematics *college_job_prop + 
                        major_category_Engineering *college_job_prop, 
                        data = training_data)


# anova test
Anova(model.interacts)
```

```{r interactions}

# reduced model after running Anova test 
model.inter_reduced <- lm(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen,  
                        data = training_data)
   
anova(model.interacts, model.inter_reduced)
```

```{r compare_models}
# compare model with and without interactions 
interactions_cv <- train(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen, 
                      data = training_data, method = "lm", trControl = tc)

interactions_cv.rmse <- interactions_cv$results[, "RMSE"]

interactions_cv.rmse

```

### Diagnostics 

```{r diagnostics_plot}
plot(model.inter_reduced)
```
```{r outliers_diagnostics}
# outlier rows 
training_data[c(14, 33, 74, 87),]

# refit model with the outliers 
interactions_no_outliers <- train(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen, 
                      data = training_data[-c(14, 33, 74, 87),], method = "lm", trControl = tc)


# see CV RMSE
interactions_no_outliers.rmse <- interactions_no_outliers$results[, "RMSE"]
interactions_no_outliers.rmse
```



```{r Bootstrap}
#bootstrap for confidence interval
modeling <- lm(log_median ~
                        rank + sharewomen +
                        employed + employed_fulltime_yearround +
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics +
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen,
                      data = training_data[-c(14, 33, 74, 87),])
#setting up nonparametric bootstrap
set.seed(11)
crg_data <- as.matrix(subset(crg,select=-c(median, major_code, p25th, p75th, major)))
sampling_size <- sample(dim(crg_data)[1],nrow(crg_data)*0.5)
sample_dist <- data.frame(crg_data[sampling_size,])
any(is.na(sample_dist))
#bootstrap function
get_coef_resample <- function(){
   #makes a resample from sample dist
   resample <- sample_n(sample_dist, size = nrow(sample_dist),replace = TRUE)
   slopes <- lm(log_median ~
                        rank + sharewomen +
                        employed + employed_fulltime_yearround +
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics +
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen,
                      data = resample) %>% coef()
   return(slopes)
}
nonpara_slopes <- t(replicate(1000,get_coef_resample()))
#nonpara_slopes[,8] #math coef has na values
as.data.frame(nonpara_slopes)
any(is.na(nonpara_slopes)) #checking if there're any NA
nonpara_slopes <- na.omit(nonpara_slopes) #removing na values
for(i in 1:ncol(nonpara_slopes)){hist(nonpara_slopes[,i])} #hist of each coef
summary(modeling)
nrow(nonpara_slopes)
col_CI = 1
CI <- nonpara_slopes[order(nonpara_slopes[,col_CI]),]
cbind(CI[25,col_CI],modeling$coefficients[col_CI],CI[975,col_CI])
#checking if model is in 95% CI
is_in_CI <- NULL
for(i in 1:ncol(nonpara_slopes)){
   CI <- nonpara_slopes[order(nonpara_slopes[,i]),] #orders data based on ith col
   
   print(CI[25,i],CI[975,i])
   if(CI[25,i] <= modeling$coefficients[i] & modeling$coefficients[i] <= CI[975,i]){
      is_in_CI <- c(TRUE,is_in_CI)
   } else {
      is_in_CI <- c(FALSE,is_in_CI)
   }
}
modeling %>% summary()
```



