---
title: "What kind of median earnngs to expect from a type of major"
author: "Kelly Trinh, Hanfei Sun, and Nathan Lam"
output: html_document
---


\newpage
## Introduction

#### Research question 
Not all college students are informed about how the choice of their major can impact their earnings after graduation. We aim to provide an overview for college students of the financial standing of graduates from different majors categories. Our research question is: 

**Given a major category, what factors contribute to how high my median income as a full-time, year-round worker?**

We will be building an linear regression model to find an association between major category and median income.

#### Dataset 
The dataset we used is the recent-grad dataset from the fivethirtyeight package. 
https://www.rdocumentation.org/packages/fivethirtyeight/versions/0.6.1/topics/college_recent_grads

It contains income and other information about 16 different major categories.
Below is a detailed description of each variable given in the dataset: 

|Header            |	Description                                   |
|------------------|------------------------------------------------|
`Rank` | Rank by median earnings 
`Major_code` | Major code
`Major`	| Major description 
`Major_category`	| Category of major 
`Total` |	Total number of people with major
`Sample_size` |	Sample size of full-time, year-round
`Men`	| Male graduates
`Women`	| Female graduates
`ShareWomen` |	Proportion of women
`Employed` |	Number employed 
`Full_time`	| Employed 35 hours or more
`Part_time` |	Employed less than 35 hours
`Full_time_year_round` |	Employed at least 50 weeks and at least 35 hours 
`Unemployed` |	Number unemployed 
`Unemployment_rate` |	Unemployed / (Unemployed + Employed)
`Median` |	Median earnings of full-time, year-round workers
`P25th` |	25th percentile of earnings
`P75th` |	75th percentile of earnings
`College_jobs` |	Number with job requiring a college degree
`Non_college_jobs` |	Number with job not requiring a college degree
`Low_wage_jobs` |	Number in low-wage service jobs

## Final model selected 

The selected model we chose includes the following variables, with the two last variables being the interaction terms between dummy variable `major_category_Engineering` and variables `rank` and `sharewomen`:

`rank`,`sharewomen`,`employed`, `employed_fulltime_yearround`, `college_job_prop`, 
`major_category_Biology...Life.Science`, `major_category_Computers...Mathematics`, `major_category_Engineering`, `major_category_Engineering * rank`, and `major_category_Engineering * sharewomen`.


**(alternate)**
\[log_median ~ rank + sharewomen + employed + employed_fulltime_yearround + college_job_prop + major_category_Biology...Life.Science + major_category_Computers...Mathematics + major_category_Engineering + major_category_Engineering * rank + major_category_Engineering * sharewomen\]

We arrived at the final model by performing two round of variable selection. The first round we only consider the existing variables (no interaction terms) using a combination of forward selection, backward selection, and leave-one-out cross validation (LOOCV). The second round we considered interaction terms and used the Analysis of Variance test to determine which terms we should keep in the model. Our diagnostic plots and bootstrap distributions of the coefficients show that the data sufficiently meets the assumption linear regression involving constant variance in the errors, linearity, and normality. Therefore, we decide that an OLS model is sufficient after removing some points with high influence.  

## Model results and limitations 

Coefficient interpretations: **(insert here)**



Here are some limitations of our model: 

(model only cares about which model influences higher pay, not a comparison between majors)
1. Our final model only contain 3 out of 16 major categories. Therefore, if a student want to know about how major categories not included in the model variables are compared, the model will not provide that information. For example, if the student wants to know how major categories `Social Science` or `Health` compares, the model will not give much information. 

2. The two methods of variable selection (backward/forward versus Analysis of Variance/ANOVA) each do not guarantee to select the best subset of explanatory variables. Backward/forward selection add variable step-wise, so it behaves more as a local optimizer than a global optimizer. The ANOVA test relies on the assumption that the data behaves in a normal distribution, and since it utilizes p-values, there is a possibility of wrongly rejecting the null.  

3. For each major category thereâ€™s only around 5-15 rows, some majors such as `Interdisciplinary` only have 1 row. The results of the model may be more reliable if there is more rows per major category. 

**(alternate)**
3. Each major category is not equally represented proportionally, some majors such as `Interdisciplinary` only have 1 row. The results of the model may be more reliable if there is more rows per major category.

4. The model doesn't explain the following confounding variables:
- The universities the students attend: some universities have stronger connections to certain industries or are located in more advantageous locations. For example, UC Berkeley has strong connections with Silicon Valley, meaning that computer science and technology students may have better chances to land higher paying jobs. On the other hand, Arts students at Berkeley would not have the same advantages. 
- Location where the students work: pay may vary highly depending on the location worked. For example, consulting jobs in New York may have higher pay compared to Nevada due to the prices of each location. 
- Financial background of the students: students from higher-income families tend to be more well-equipped to land a high-paying job early in their careers. 
- The industries the student go to: some students may not choose to go to an unrelated compared to their major. For example, an Arts student choose to work in an investment banking firm such as JP Morgan will have very different salaries compared to an Arts student who becomes an architect.

**(alternate)**
-Context can heavily influence a student's trajectory. Things like financial background, location of university, and type of university can offer students more or less resources needed for better chances of higher pay and thus can influence median income.

5. Other model-building methods we should consider include: finding a better way to treat NaN values instead of omitting them, trying alternative cross-validation methods (such as k-fold cross validation), and considering non-linear models (our diagnostics show that our data show linearity but our analysis will be more rigorous if we compare our OLS model and non-linear models).

**(alternate)**
5. Alternative steps future studies can make:
- change method on dealing with missing values; filling in missing values instead of omitting them.
- Change method of cross validation
- Consider nonlinear model

## Conclusions on main findings 

*** 
Summarize conclusions 
***

Some improvements we could implement into our model:
1. We may want to manually add major categories that were not selected in our model, or we could combine some major categories together depending on their relatedness (for example, combining `Physical Sciences` and `Biology & Life Sciences`), which may allow for our final model include more major category variables.
2. We also might try an exhaustive selection method and trying out different cross validation methods. 
3. Finally, we can collect more data to add more information on confounding variables or add more rows per major category. 

## Additional work 

```{r setup, echo = FALSE, message=FALSE, warning=FALSE}
library(fivethirtyeight) #source of data
library(corrplot) #correlation plot
library(dplyr) #data frame manipulation
library(ggplot2) #plotting
library(leaps)#variable selection: adjr2, bic, cp
library(car) # Anova
library(fastDummies)#dummy variables
library(faraway)
library(caret)
```



### EDA and data cleaning 

Here are some modifications we did to our data:

1. The target variable `median` is right-skewed, so we log transformed it.

2. There is only one row with missing variables, so we omitted the row.

3. When examining the correlation plots, we see that many variables are highly correlated. For example, `college_jobs`, `employed_fulltime`, `employed_parttime` are highly correlated. We transforms some of these variables into `college_job_prop` and `full_time_yearround_prop`, which gives the proportions rather than an absolute number. We believe these variables would be less correlated with other explanatory variables. 

4. We standardized continuous variables to prepare for variable selection and transformed categorical variables into dummies.

5. We also performed a test-train split; the test set will be used to guard against overfitting and to build prediction intervals. 


```{r data_cleaning, echo = F, fig.cap = "Figure 1: Correlation Heat Map", out.width = "50%",fig.align='center'}
# load data
crg <- college_recent_grads
crg <- na.omit(crg)

# viewing correlations 
crg["log_median"] <- log(crg$median)
crg["college_job_prop"] <- crg$college_jobs / (crg$college_jobs + crg$non_college_jobs)
crg["full_time_yearround_prop"] <- crg$employed_fulltime_yearround / crg$employed
crg <- na.omit(crg)
cont <- select_if(crg, is.numeric)
cont <- na.omit(cont)


#correlation between continuous variables
corrrr <- reshape2::melt(cor(cont), 
                      varnames = paste0("variables", 1:2), 
                      value.name = "Correlation")

ggplot(corrrr, aes(variables1, variables2, fill = Correlation)) + 
  geom_tile(color="white") + 
  scale_fill_gradient2(low="blue",
                       high="red",
                       mid="white",
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Correlation") +
  labs(x="",y="",title = "Correlation Heat Map",
       caption ="Figure 1") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1), plot.title = element_text(hjust = 0.5))



# transform data
standardized <- data.frame(scale(cont))
major_category <- crg$major_category
crg <- cbind(standardized, major_category)

# temporary data frame to use later 
temp <- crg 

# transform categorical variable 
crg <- dummy_cols(crg, select_columns = "major_category", remove_selected_col = TRUE,remove_first_dummy = TRUE)
column_names <- make.names(names(crg),unique=TRUE)
colnames(crg) <- column_names

# test train split 
set.seed(11)
#randomly take 2:8 of data for training
training_size <- sample(dim(crg)[1],nrow(crg)*0.8)
training_data <- crg[training_size,]
testing_data <- crg[-training_size,]

```
  
We also created an overview of the distribution of median incomes from different major categories.  
```{r visualizations, echo = F, out.width = "50%",fig.align='center'}

# major category versus median income 
ggplot(aes(x = major_category, y = log_median), data = temp) + 
   geom_boxplot() + 
   coord_flip() +
   labs(title = "Major category vs median income", 
        caption = "Figure 2")

```

**(needs improement)**
Looking at Figure 1, there are a lot of variables highly correlated with each other, particularly for variables that are already similar to each other, like type of job or type of employment. High correlation can be good to help explain median income, but it also comes with the risk of collinearity. In Figure 2, we look at how log_median is spread out among various major categories. The most apparent thing is seeing how much money Engineering gets. If a category 
  
Using the alias function on a lm object with all variables reveals which variables are collinear, this turned out to be the variables total and men. We removed men as well as the variables major_code, p25th, and p75th as they do not benefit the model.


### Model selection

#### Methodology 

As mentioned above, we performed two rounds of variable selection. We started with backward/forward selection.
We note that this method requires standardizing continuous variable, and this method doesn't obey the principle of marginality nor treat the variable `major_category` as a single category. Therefore, in this round of variable selection, we do not consider interaction terms. This task is left to the second round of variable selection where we used an ANOVA test that works better with categorical and interaction terms. The first round helps us select which variables to include in the model, and we will create interaction terms from the selected variables. The second round helps us determine which newly created interaction terms to include in the model in addition to the variables selected from the first round. 

We used backward and forward selection to filter out the existing variables; we consider interaction terms later. We produced six models: the 3 best models selected by backward selection in terms of Mallow's Cp, BIC, and adjusted R squared; and the 3 best models selected by forward selection using the same criterias. To decide between the 6 models, we performed leave-one-out cross validation (LOOCV) and calculated the root mean squared error (RMSE). We select the model with the lowest LOOCV RMSE, which is the model selected using backward selection with adjusted R squared as a criteria (this selected model is the same model chosen from backward selection using Mallow's Cp). The selected model without interaction terms has RMSE of `0.2435908`. We ensure to check for overfitting by training the selected model using the training set, predict on the testing set, and look at the sum of error squared and the correlation between the fitted values and the actual values. 

Next, we consider adding interaction terms. We used the Analysis of Variance test to determine which interaction terms to add to the model. To compare this model and the model without interaction terms, we again calculate the LOOCV RMSE for the former and compare with the RMSE of the latter. We found that the model with interaction terms perform better; specficially its LOOCV RMSE is `0.1933749`.



```{r prepare_data_for_selection, include = F}
unique(college_recent_grads$major_category)
nrow(college_recent_grads[college_recent_grads$major_category %in% 
      c("Computers & Mathematics", "Biology & Life Science", "Engineering"), ])

Y <- as.matrix(crg$log_median)
X <- as.matrix(subset(crg,select=-c(log_median,median, major_code, p25th, p75th)))

# Check for linear dependencies, remove "men" or "total"
alias(lm(Y~X))

#removing men because of collinearity
X <- as.matrix(subset(crg,select=-c(log_median,median, major_code, p25th, p75th,  men)))
```

#### Variable selection without interactions: backward/forward/cross-validation 

```{r backward_forward_selection, include = F}

#########Forward Selection#########
f_model <- regsubsets(x = X, y = Y, method = "forward", nbest = 1) %>% summary()

#extracting criterion
f_adjustr2 <- f_model$adjr2
f_BIC <- f_model$bic
f_mallow_Cp <- f_model$cp

#picking best variables
f_adjr2_picked <- f_model$which[which.max(f_adjustr2),]
f_BIC_picked <- f_model$which[which.min(f_BIC),]
f_cp_picked <- f_model$which[which.min(f_mallow_Cp),]

#printing picked variables
f_adjr2_picked[f_adjr2_picked == TRUE]
f_BIC_picked[f_BIC_picked == TRUE]
f_cp_picked[f_cp_picked == TRUE]



#########Backward Selection#########
b_model <- regsubsets(x = X, y = Y, method = "backward", nbest = 1) %>% summary()

#extracting criterion
b_adjustr2 <- b_model$adjr2
b_BIC <- b_model$bic
b_mallow_Cp <- b_model$cp

#picking best variables
b_adjr2_picked <- b_model$which[which.max(b_adjustr2),]
b_BIC_picked <- b_model$which[which.min(b_BIC),]
b_cp_picked <- b_model$which[which.min(b_mallow_Cp),]

#printing picked variables
b_adjr2_picked[b_adjr2_picked == TRUE]
b_BIC_picked[b_BIC_picked == TRUE]
b_cp_picked[b_cp_picked == TRUE]

```

```{r forward_backward_visualized, echo = F, fig.cap = "Figure 3: Progression of variable selection"}
par(mfrow=c(2,3))
plot(f_adjustr2, xlab = "Number of variables",ylab = "Forward Adjusted R squared", type = "l")
points(which.max(f_adjustr2), max(f_adjustr2), col = "red")
plot(f_BIC, xlab = "Number of variables",ylab = "Forward BIC", type = "l")
points(which.min(f_BIC), min(f_BIC), col = "red")
plot(f_mallow_Cp, xlab = "Number of variables",ylab = "Forward Mallow's Cp", type = "l")
points(which.min(f_mallow_Cp), min(f_mallow_Cp), col = "red")
###
plot(b_adjustr2, xlab = "Number of variables",ylab = "Backward Adjusted R squared", type = "l")
points(which.max(b_adjustr2), max(b_adjustr2), col = "red")
plot(b_BIC, xlab = "Number of variables",ylab = "Backward BIC", type = "l")
points(which.min(b_BIC), min(b_BIC), col = "red")
plot(b_mallow_Cp, xlab = "Number of variables",ylab = "Backward Mallow's Cp", type = "l")
points(which.min(b_mallow_Cp), min(b_mallow_Cp), col = "red")
mtext("Forward Variable Selection",side=3,line=-2,outer=TRUE)
mtext("Backward Variable Selection",side=3,line=-22,outer=TRUE)


```

```{r backward_adjusted_r_squared, include= F}
# Backward Adjusted R-squared CV
tc <- trainControl(method = "LOOCV")
b_adjr2_mod_cv <- train(log_median ~ employed + employed_fulltime_yearround + 
                          college_job_prop +
                          major_category_Biology...Life.Science+
                          major_category_Computers...Mathematics + 
                          rank + sharewomen + major_category_Engineering , 
                        data = training_data, method = "lm", trControl = tc)
b_adjr2_mod_cv.rmse <- b_adjr2_mod_cv$results[,"RMSE"]

```


```{r backward_bic, include= F}
# Backward BIC CV
b_bic_mod_cv <- train(log_median ~ rank + college_job_prop +  
                         major_category_Engineering, 
                      data = training_data, method = "lm", trControl = tc )
b_bic_mod_cv.rmse <- b_bic_mod_cv$results[, "RMSE"]
```

```{r backward_mallow_cp, include = F}
# Backward Mallow's Cp CV
b_cp_mod_cv <- train(log_median ~ employed + employed_fulltime_yearround + 
                       college_job_prop +  major_category_Biology...Life.Science
                     + major_category_Computers...Mathematics + rank +
                       major_category_Engineering + sharewomen , data = training_data , 
                     method = "lm", trControl = tc)
b_cp_mod_cv.rmse <- b_cp_mod_cv$results[, "RMSE"]
```


```{r forward_all_three_criterias, include= F}
# Forward Adjusted R-squared CV
f_adjr2_model_cv <- train(log_median ~ rank + unemployment_rate + 
                           college_job_prop + major_category_Arts + 
                           major_category_Biology...Life.Science  + 
                           major_category_Engineering  + 
                           major_category_Humanities...Liberal.Arts  + 
                           major_category_Industrial.Arts...Consumer.Services , 
                           data = training_data, method = "lm", trControl = tc)

f_adjr2_model_cv.rmse <- f_adjr2_model_cv$results[, "RMSE"]

# Forward BIC CV
f_BIC_model_cv <- train(log_median ~ rank + college_job_prop + 
                           major_category_Engineering, 
                       data = training_data, method = "lm", trControl = tc)

f_BIC_model_cv.rmse <- f_BIC_model_cv$results[, "RMSE"]

# Forward Mallow's Cp CV
f_Cp_model_cv <- train(log_median ~ rank + unemployment_rate + 
                          college_job_prop + major_category_Arts + 
                         major_category_Engineering + 
                         major_category_Humanities...Liberal.Arts, 
                      data = training_data, method = "lm", trControl = tc)

f_Cp_model_cv.rmse <- f_Cp_model_cv$results[, "RMSE"]
```

```{r check_overfitting, echo = F}
#checking for overfitting
#if the model overfits, it shouldnt be able to predict the test set that well

# model selected from backward/forward selection 
model.backfor <- lm(log_median ~ employed + employed_fulltime_yearround + 
                          college_job_prop +
                          major_category_Biology...Life.Science+
                          major_category_Computers...Mathematics + 
                          rank + sharewomen + major_category_Engineering, 
                    data = training_data)

model.backfor_predict <- predict(model.backfor, newdata = testing_data, type = "response")

# sum of error squared 
SSR <- sum((testing_data$log_median - model.backfor_predict)^2)
cat("Sum of Errors Squared: ", SSR)

# correlation between actual values and predicted values 
cor_predict <- cor(model.backfor_predict, testing_data$log_median)**2
cat("Correlation between the predicted values and actual values: ", cor_predict)

```


Summary table description: 

`forward.rmse` and `backward.rmse` are columns with the RMSE from prediction on the testing dataset depending on either forward selection or backward selection. 
Each of the row represent the criteria in which to choose the model from either forward or backward selection: `Adjusted R squared`, `BIC`, `Mallow's Cp`. 

```{r CV_rmse_summary, echo = F}

criterias <- c("Adjusted R squared", "BIC", "Mallow's Cp")
forward.rmse <- c(f_adjr2_model_cv.rmse, f_BIC_model_cv.rmse, f_Cp_model_cv.rmse)
backward.rmse <- c(b_adjr2_mod_cv.rmse, b_bic_mod_cv.rmse, b_cp_mod_cv.rmse)

# table of RMSE of each model 
data.frame(criterias, forward.rmse, backward.rmse)
```

#### Variable selection with interactions 

To examine possible interaction terms, we look at coplots, created on the training data set with standardized continuous variables. The coplots show that `sharewomen` and `employed_fulltime_yearround` seem to have interactions with `major_category`. However, these coplots are inconclusive, so we will run an Analysis of Variance test to determine which interaction terms to keep. 

```{r coplots, warning=FALSE, message=FALSE, echo = F}
#interactions

# temp dataframe for co-plots
temp.training <- temp[temp$rank %in% training_data$rank,]
temp.coplot <- temp.training[temp.training$major_category %in% 
                               c("Biology & Life Science",
                                 "Computers & Mathematics", 
                                 "Engineering"), ]


# share women and median income 
xyplot(log_median ~ sharewomen | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})

# rank and median income 
xyplot(log_median ~ rank | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})

# college job proportion and median income 
xyplot(log_median ~ college_job_prop | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})

# employed fulltime and median income 
xyplot(log_median ~ employed_fulltime_yearround | major_category, data = temp.coplot ,
       panel = function(x, y) {
panel.xyplot(x, y, type = c("p", "smooth", "r"))
})


```
  
We will keep all the original terms (not interaction terms) and will use the Analysis of Variance test to determine which interaction terms to add. This test, unlike the coplots shown above, show that interaction terms `rank:major_category_Engineering` and `sharewomen:major_category_Engineering` have significant p-values. We will include those variables in our final selected model. 

```{r full_model_interactions, include = F}
# model selected from backward/forward selection 
model.backfor <- lm(log_median ~ employed + employed_fulltime_yearround + 
                          college_job_prop +
                          major_category_Biology...Life.Science+
                          major_category_Computers...Mathematics + 
                          rank + sharewomen + major_category_Engineering, 
                    data = training_data)

# full model with all the interaction terms 
model.interacts <- lm(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Biology...Life.Science * rank+
                        major_category_Computers...Mathematics * rank+ 
                        major_category_Engineering * rank +
                        major_category_Biology...Life.Science * sharewomen+
                        major_category_Computers...Mathematics * sharewomen + 
                        major_category_Engineering * sharewomen +
                        major_category_Biology...Life.Science * employed_fulltime_yearround+
                        major_category_Computers...Mathematics * employed_fulltime_yearround+ 
                        major_category_Engineering * employed_fulltime_yearround+
                        major_category_Biology...Life.Science * college_job_prop+
                        major_category_Computers...Mathematics *college_job_prop + 
                        major_category_Engineering *college_job_prop, 
                        data = training_data)


# anova test
Anova(model.interacts)
```

```{r interactions, include = F}

# reduced model after running Anova test 
model.inter_reduced <- lm(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen,  
                        data = training_data)
   
anova(model.interacts, model.inter_reduced)
```

```{r compare_models, include = F}
# compare model with and without interactions in terms of LOOCV RMSE
interactions_cv <- train(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen, 
                      data = training_data, method = "lm", trControl = tc)

interactions_cv.rmse <- interactions_cv$results[, "RMSE"]

interactions_cv.rmse

```

#### Results

After considering the interaction terms, the selected model we chose includes the following variables:
`rank`,`sharewomen`,`employed`, `employed_fulltime_yearround`, `college_job_prop`, 
`major_category_Biology...Life.Science`, `major_category_Computers...Mathematics`, `major_category_Engineering`, `major_category_Engineering * rank`, and `major_category_Engineering * sharewomen`.

### Diagnostics 

We then perform diagnostics on outliers and assumptions. From the `Residuals vs Fitted` and `Scale-Location` plots, we see that there's no pattern in the studentized residuals against the fitted values, so we conclude that the response variable has a quite linear relationship with the explanatory variables, and the errors have constant residuals. Based on the `QQ plot`, we see that most of the data lines around the theoretical line well, meaning that the response variable is somewhat normally distributed. However, according to the `Residuals vs Leverage` plot, there are some outliers with higher Cook's distance, notably. Below, we fitted the model selected above without these points. We calculate the LOOCV RMSE of this new model. 

```{r diagnostics_plot, echo = F, fig.cap = "Figure 5: Diagnosis plots"}
par(mfrow=c(2,2))
plot(model.inter_reduced)
```

```{r outliers_diagnostics, echo = F}
# outlier rows 
training_data[c(14, 33, 74, 87),]

# refit model with the outliers 
interactions_no_outliers <- train(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen, 
                      data = training_data[-c(14, 33, 74, 87),], method = "lm", trControl = tc)


# see CV RMSE
interactions_no_outliers.rmse <- interactions_no_outliers$results[, "RMSE"]
interactions_no_outliers.rmse
```

### Prediction


```{r predictions, echo = F}

# final model selected 

model.final <- lm(log_median ~ 
                        rank + sharewomen + 
                        employed + employed_fulltime_yearround + 
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics + 
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen, 
                      data = training_data[-c(14, 33, 74, 87),])
                  

# new data from testing set 
set.seed(11)
new_data1 <- testing_data[sample(nrow(testing_data), 1), ]


# reporting prediction intervals (standardized)
predict.standard <- predict(model.final, newdata = new_data1, interval = "predict")
predict.standard

# bring back to original scale 
predict.original <- exp(predict.standard * sd(log(college_recent_grads$median)) + mean(log(college_recent_grads$median)))

# get data from original data table
new_data1.rank <- new_data1[,1] * sd(college_recent_grads$rank) + mean(college_recent_grads$rank)
temp1 <- cbind(predict.original, college_recent_grads[ceiling(new_data1.rank), ]$median)
colnames(temp1) <- c(colnames(predict.standard), "actual")

# compare predicted data and actual value
temp1

```

### Reporting 


```{r Bootstrap, include = F}
#bootstrap for confidence interval

modeling <- lm(log_median ~
                        rank + sharewomen +
                        employed + employed_fulltime_yearround +
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics +
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen,
                      data = training_data[-c(14, 33, 74, 87),])


#setting up nonparametric bootstrap
set.seed(11)
crg_data <- as.matrix(subset(crg,select=-c(median, major_code, p25th, p75th)))
sampling_size <- sample(dim(crg_data)[1],nrow(crg_data)*0.5)
sample_dist <- data.frame(crg_data[sampling_size,])

any(is.na(sample_dist))



#bootstrap function
get_coef_resample <- function(){
   #makes a resample from sample dist
   resample <- sample_n(sample_dist, size = nrow(sample_dist),replace = TRUE)


   slopes <- lm(log_median ~
                        rank + sharewomen +
                        employed + employed_fulltime_yearround +
                        college_job_prop +
                        major_category_Biology...Life.Science+
                        major_category_Computers...Mathematics +
                        major_category_Engineering +
                        major_category_Engineering * rank +
                        major_category_Engineering * sharewomen,
                      data = resample) %>% coef()
   return(slopes)
}

nonpara_slopes <- t(replicate(1000,get_coef_resample()))
#nonpara_slopes[,8] #math coef has na values
as.data.frame(nonpara_slopes)
any(is.na(nonpara_slopes)) #checking if there're any NA
nonpara_slopes <- na.omit(nonpara_slopes) #removing na values
for(i in 1:ncol(nonpara_slopes)){hist(nonpara_slopes[,i])} #hist of each coef
summary(modeling)
nrow(nonpara_slopes)
col_CI = 1
CI <- nonpara_slopes[order(nonpara_slopes[,col_CI]),]
cbind(CI[25,col_CI],modeling$coefficients[col_CI],CI[975,col_CI])



nonpara_slopes <- t(replicate(1000,get_coef_resample()))
#nonpara_slopes[,8] #math coef has na values

as.data.frame(nonpara_slopes)

any(is.na(nonpara_slopes)) #checking if there're any NA
nonpara_slopes <- na.omit(nonpara_slopes) #removing na values


for(i in 1:ncol(nonpara_slopes)){hist(nonpara_slopes[,i])} #hist of each coef
summary(modeling)

nrow(nonpara_slopes)


col_CI = 1
CI <- nonpara_slopes[order(nonpara_slopes[,col_CI]),]
cbind(CI[25,col_CI],modeling$coefficients[col_CI],CI[975,col_CI])


#checking if model is in 95% CI
is_in_CI <- NULL
for(i in 1:ncol(nonpara_slopes)){
   CI <- nonpara_slopes[order(nonpara_slopes[,i]),] #orders data based on ith col
   
   print(CI[25,i],CI[975,i])


   if(CI[25,i] <= modeling$coefficients[i] & modeling$coefficients[i] <= CI[975,i]){
      is_in_CI <- c(TRUE,is_in_CI)
   } else {
      is_in_CI <- c(FALSE,is_in_CI)
   }
}

```




